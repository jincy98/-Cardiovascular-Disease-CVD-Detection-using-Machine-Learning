{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46f1d885-bf0b-4844-bc87-e7bbf8517897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "167081b3-9bce-4ddc-94ed-3b96dcf02a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94756207-4a70-4cd9-b4dd-0f63a1dffa26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Model  Accuracy  Precision    Recall  F1 Score   ROC AUC\n",
      "3       Gradient Boosting  0.739039   0.748215  0.655486  0.698788  0.794329\n",
      "6                 XGBoost  0.725650   0.732877  0.638715  0.682564  0.782282\n",
      "4                AdaBoost  0.732738   0.760732  0.614554  0.679874  0.789342\n",
      "0     Logistic Regression  0.727619   0.754677  0.607732  0.673280  0.773992\n",
      "2           Random Forest  0.705697   0.694631  0.647243  0.670100  0.763095\n",
      "1           Decision Tree  0.635994   0.604313  0.613417  0.608831  0.634391\n",
      "5  Support Vector Machine  0.538199   0.000000  0.000000  0.000000  0.732641\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "# Optional: XGBoost\n",
    "try:\n",
    "    from xgboost import XGBClassifier\n",
    "    xgb_available = True\n",
    "except ImportError:\n",
    "    xgb_available = False\n",
    "\n",
    "\n",
    "X = df.drop(columns=['cardio'])  # Replace with your actual target\n",
    "y = df['cardio']\n",
    "\n",
    "# 3. Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 4. Define Models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Support Vector Machine': SVC(probability=True)  # Enable probability=True for ROC AUC\n",
    "}\n",
    "\n",
    "if xgb_available:\n",
    "    models['XGBoost'] = XGBClassifier(use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "# 5. Evaluate Models\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_prob = model.predict_proba(X_test)[:, 1] if hasattr(model, \"predict_proba\") else y_pred\n",
    "\n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred),\n",
    "        'ROC AUC': roc_auc_score(y_test, y_prob)\n",
    "    })\n",
    "\n",
    "# 6. Show Comparison Table\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(by='F1 Score', ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab765904-0499-4757-a11e-62c4c972ebbd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e74d7112-7794-4de3-82ce-09581706c1ea",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "554981f7-dfcc-4a20-b900-1d4e22a54fc3",
   "metadata": {},
   "source": [
    "This project aimed to develop an accurate and reliable machine learning model for the early detection of cardiovascular disease (CVD) based on patient health data. Multiple classification algorithms were implemented and evaluated, including Logistic Regression, Decision Tree, Random Forest, Support Vector Machine (SVM), AdaBoost, Gradient Boosting, and XGBoost. Each model was assessed using key performance metrics such as accuracy, precision, recall, F1 score, and ROC AUC. Among all models, Gradient Boosting delivered the best performance, with the highest F1 Score (0.699) and ROC AUC (0.794), indicating its strong ability to correctly identify CVD cases while maintaining a good balance between false positives and false negatives. XGBoost and AdaBoost followed closely behind, showing competitive results. Simpler models like Logistic Regression were moderately effective and can be used where interpretability is a priority. The SVM model underperformed significantly, likely due to class imbalance or lack of tuning. In conclusion, Gradient Boosting is recommended for deployment in CVD risk prediction tasks, potentially assisting healthcare professionals in early intervention and treatment planning. Further enhancements can be achieved by tuning hyperparameters, applying cross-validation, and exploring deep learning or ensemble stacking approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5ae23b-1a03-4157-b7a6-57dc74dc9350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
